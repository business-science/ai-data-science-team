# ğŸš€ Fork Features - Enhanced AI Data Science Team

**This is an enhanced fork of [business-science/ai-data-science-team](https://github.com/business-science/ai-data-science-team)** with additional custom agents and tools.

## ğŸ†• What's New in This Fork?

This fork extends the original package with **5 additional AI agents** and **29 specialized tools** that complement the core functionality.

### Original Package Features âœ…
- Data Wrangling Agent
- Data Visualization Agent
- Data Cleaning Agent
- Feature Engineering Agent
- SQL Database Agent
- H2O ML Agent
- MLflow Tools Agent
- EDA Tools Agent
- Pandas Data Analyst (Multi-Agent)

### ğŸ‰ NEW: Custom Extensions (This Fork)

| Agent | Tools | Purpose |
|-------|-------|---------|
| **Data Quality Agent** | 5 | Schema validation, anomaly detection, quality scoring |
| **Feature Importance Agent** | 6 | Model interpretation, SHAP, importance comparison |
| **Model Comparison Agent** | 6 | Multi-model evaluation, ROC curves, rankings |
| **Outlier Detection Agent** | 6 | Multiple detection methods, treatment recommendations |
| **Time Series Agent** | 6 | Seasonality, decomposition, forecasting, stationarity |

**Total Custom Extensions:** 5 agents, 29 tools, 5,000+ lines of code

---

## ğŸ¯ Why Use This Fork?

### Original Package â†’ Great for:
- Data wrangling and cleaning
- Building ML models with H2O
- Basic EDA and visualization
- SQL data extraction

### This Fork â†’ Adds:
- **Data Quality Validation** - Catch issues before modeling
- **Model Interpretation** - Understand feature importance with SHAP
- **Model Selection** - Compare multiple models scientifically
- **Outlier Management** - Advanced detection and treatment
- **Time Series Analysis** - Comprehensive temporal data tools

**Perfect for:** Teams that need end-to-end data science workflows with quality control and model validation.

---

## ğŸ“¦ Installation

### Install from This Fork

```bash
# Clone this fork
git clone https://github.com/NicoLeeVaz/ai-data-science-team.git
cd ai-data-science-team

# Install with custom extensions
pip install -e .

# Install additional dependencies for custom features
pip install scipy statsmodels shap flask flask-cors streamlit
```

### Or Install Original Package

```bash
# Original package (without custom extensions)
pip install ai-data-science-team
```

---

## ğŸš€ Quick Start

### Using Original Package Agents

```python
from langchain_openai import ChatOpenAI
from ai_data_science_team.agents import DataWranglingAgent
import pandas as pd

llm = ChatOpenAI(model="gpt-4")
agent = DataWranglingAgent(model=llm)

# Use original agents as normal
result = agent.invoke(df, "Clean and prepare this data")
```

### Using Custom Fork Extensions

```python
from langchain_openai import ChatOpenAI
from custom.agents import (
    DataQualityAgent,
    FeatureImportanceAgent,
    ModelComparisonAgent,
    OutlierDetectionAgent,
    TimeSeriesAgent
)
import pandas as pd

llm = ChatOpenAI(model="gpt-4")

# 1. Check Data Quality
dq_agent = DataQualityAgent(model=llm)
quality_report = dq_agent.quick_check(df)
print(quality_report)

# 2. Detect Outliers
outlier_agent = OutlierDetectionAgent(model=llm)
outliers = outlier_agent.quick_detect(
    data=df,
    columns=['price', 'quantity'],
    method='iqr'
)
print(outliers['treatment_recommendations'])

# 3. Analyze Feature Importance (after training model)
fi_agent = FeatureImportanceAgent(model=llm)
importance = fi_agent.quick_importance(
    model=trained_model,
    feature_names=X.columns.tolist()
)
print(importance['report'])

# 4. Compare Models
comparison_agent = ModelComparisonAgent(model=llm)
results = comparison_agent.quick_comparison(
    predictions=predictions_dict,
    y_true=y_test,
    model_names=['RandomForest', 'XGBoost', 'LogisticRegression'],
    task_type='classification'
)
print(results['report'])

# 5. Time Series Analysis
ts_agent = TimeSeriesAgent(model=llm)
report = ts_agent.generate_report(
    data=df,
    value_column='sales',
    date_column='date'
)
print(report)
```

---

## ğŸ“– Complete Documentation

### Custom Extensions Documentation
- **[Custom Extensions Guide](custom/docs/CUSTOM_EXTENSIONS_GUIDE.md)** - Detailed docs for all 5 custom agents
- **[Usage Examples](custom/examples/README.md)** - Python, Jupyter, Streamlit, CLI, REST API examples
- **[Quick Start](custom/QUICKSTART.md)** - Build your first custom agent

### Original Package Documentation
- **[Main README](README.md)** - Original package features and usage
- **[Examples](examples/)** - Original package examples

---

## ğŸ› ï¸ Usage Methods

All custom agents work with multiple interfaces:

### 1. **Python Scripts**
```python
# analyze.py
from custom.agents import DataQualityAgent
import pandas as pd

df = pd.read_excel("data.xlsx")
agent = DataQualityAgent(model=llm)
print(agent.quick_check(df))
```

### 2. **Jupyter Notebooks**
```python
# Interactive analysis
from custom.agents import *
# ... explore data interactively
```

### 3. **Streamlit Web App** ğŸŒ
```bash
streamlit run custom/examples/streamlit_quality_checker.py
# Opens browser with drag & drop interface!
```

### 4. **Command-Line Tool** ğŸ’»
```bash
python custom/examples/cli_quality_check.py data.csv --outliers
```

### 5. **REST API + JavaScript** ğŸŒ
```bash
# Start API server
python custom/examples/api_server.py

# Use from JavaScript/React/any web app
# See: custom/examples/web_client.html
```

**Full examples:** See `custom/examples/README.md`

---

## ğŸ”‘ Key Features Comparison

| Feature | Original Package | This Fork |
|---------|-----------------|-----------|
| Data Wrangling | âœ… | âœ… |
| Data Cleaning | âœ… | âœ… |
| Feature Engineering | âœ… | âœ… |
| H2O AutoML | âœ… | âœ… |
| MLflow Integration | âœ… | âœ… |
| EDA Tools | âœ… | âœ… |
| **Data Quality Validation** | âŒ | âœ… **NEW** |
| **Schema Compliance** | âŒ | âœ… **NEW** |
| **Business Rule Validation** | âŒ | âœ… **NEW** |
| **Feature Importance (SHAP)** | âŒ | âœ… **NEW** |
| **Multi-Model Comparison** | âŒ | âœ… **NEW** |
| **ROC Curve Comparison** | âŒ | âœ… **NEW** |
| **Advanced Outlier Detection** | âŒ | âœ… **NEW** |
| **Isolation Forest** | âŒ | âœ… **NEW** |
| **LOF (Local Outlier Factor)** | âŒ | âœ… **NEW** |
| **Time Series Analysis** | âŒ | âœ… **NEW** |
| **Seasonality Detection** | âŒ | âœ… **NEW** |
| **Stationarity Testing** | âŒ | âœ… **NEW** |
| **Baseline Forecasting** | âŒ | âœ… **NEW** |
| **Streamlit Examples** | âŒ | âœ… **NEW** |
| **REST API Server** | âŒ | âœ… **NEW** |
| **CLI Tools** | âŒ | âœ… **NEW** |

---

## ğŸ’¡ Common Workflows

### Workflow 1: Data Quality â†’ Modeling â†’ Comparison

```python
from langchain_openai import ChatOpenAI
from custom.agents import DataQualityAgent, OutlierDetectionAgent, ModelComparisonAgent
from ai_data_science_team.ml_agents import H2OMLAgent
from sklearn.ensemble import RandomForestClassifier
import pandas as pd

llm = ChatOpenAI(model="gpt-4")

# Step 1: Load data
df = pd.read_csv("customer_data.csv")

# Step 2: Check quality (CUSTOM)
dq_agent = DataQualityAgent(model=llm)
quality = dq_agent.quick_check(df)
print("Quality Score:", quality)

# Step 3: Handle outliers (CUSTOM)
outlier_agent = OutlierDetectionAgent(model=llm)
outlier_indices = outlier_agent.get_consensus_outliers(
    data=df,
    columns=['age', 'income', 'credit_score'],
    methods=['zscore', 'iqr'],
    min_methods=2
)
df_clean = df.drop(outlier_indices)

# Step 4: Train models (ORIGINAL + Custom)
# Option A: Use original H2O ML Agent
h2o_agent = H2OMLAgent(model=llm)
h2o_agent.invoke_agent(
    data_raw=df_clean,
    user_instructions="Build classification model for 'churn'",
    target_variable="churn"
)

# Option B: Train your own models
rf = RandomForestClassifier()
rf.fit(X_train, y_train)

# Step 5: Compare models (CUSTOM)
comparison_agent = ModelComparisonAgent(model=llm)
results = comparison_agent.quick_comparison(
    predictions={
        'H2O_Best': h2o_predictions,
        'RandomForest': rf.predict(X_test)
    },
    y_true=y_test,
    model_names=['H2O_Best', 'RandomForest'],
    task_type='classification'
)
print(results['report'])
```

### Workflow 2: Time Series Pipeline

```python
from langchain_openai import ChatOpenAI
from custom.agents import DataQualityAgent, TimeSeriesAgent
from ai_data_science_team.agents import DataWranglingAgent
import pandas as pd

llm = ChatOpenAI(model="gpt-4")

# Step 1: Wrangle data (ORIGINAL)
wrangling_agent = DataWranglingAgent(model=llm)
df_clean = wrangling_agent.invoke(df, "Clean and prepare time series data")

# Step 2: Quality check (CUSTOM)
dq_agent = DataQualityAgent(model=llm)
quality = dq_agent.quick_check(df_clean)

# Step 3: Time series analysis (CUSTOM)
ts_agent = TimeSeriesAgent(model=llm)

# Detect patterns
patterns = ts_agent.detect_patterns(
    data=df_clean,
    value_column='sales',
    date_column='date'
)
print(f"Seasonality: {patterns['seasonality_found']}")

# Create forecasts
forecasts = ts_agent.create_forecast(
    data=df_clean,
    value_column='sales',
    date_column='date',
    forecast_periods=30,
    methods=['naive', 'drift', 'seasonal_naive']
)

# Generate report
report = ts_agent.generate_report(df_clean, 'sales', 'date')
print(report)
```

---

## ğŸ—ï¸ Architecture

### Custom Extensions Structure

```
ai-data-science-team/
â”œâ”€â”€ ai_data_science_team/          # Original package
â”‚   â”œâ”€â”€ agents/                    # Original agents
â”‚   â”œâ”€â”€ ml_agents/                 # H2O, MLflow agents
â”‚   â”œâ”€â”€ tools/                     # Original tools
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ custom/                        # ğŸ†• CUSTOM EXTENSIONS (This Fork)
â”‚   â”œâ”€â”€ agents/                    # 5 custom agents
â”‚   â”‚   â”œâ”€â”€ data_quality_agent.py
â”‚   â”‚   â”œâ”€â”€ feature_importance_agent.py
â”‚   â”‚   â”œâ”€â”€ model_comparison_agent.py
â”‚   â”‚   â”œâ”€â”€ outlier_detection_agent.py
â”‚   â”‚   â””â”€â”€ time_series_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                     # 29 custom tools
â”‚   â”‚   â”œâ”€â”€ data_quality.py        # 5 tools
â”‚   â”‚   â”œâ”€â”€ feature_importance.py  # 6 tools
â”‚   â”‚   â”œâ”€â”€ model_comparison.py    # 6 tools
â”‚   â”‚   â”œâ”€â”€ outlier_detection.py   # 6 tools
â”‚   â”‚   â””â”€â”€ time_series.py         # 6 tools
â”‚   â”‚
â”‚   â”œâ”€â”€ examples/                  # Usage examples
â”‚   â”‚   â”œâ”€â”€ streamlit_quality_checker.py
â”‚   â”‚   â”œâ”€â”€ cli_quality_check.py
â”‚   â”‚   â”œâ”€â”€ api_server.py
â”‚   â”‚   â”œâ”€â”€ web_client.html
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ docs/                      # Documentation
â”‚   â”‚   â””â”€â”€ CUSTOM_EXTENSIONS_GUIDE.md
â”‚   â”‚
â”‚   â””â”€â”€ private/                   # Your private work (gitignored)
â”‚
â””â”€â”€ FORK_FEATURES.md               # This file
```

---

## ğŸ” Safety & Isolation

This fork is configured with safety guardrails to prevent accidental merging back to upstream:

âœ… **Upstream push disabled** - Cannot accidentally push to original repo
âœ… **Custom code isolated** - All custom work in `custom/` directory
âœ… **Private workspace** - `custom/private/` for sensitive code (gitignored)
âœ… **Independent versioning** - Your fork, your releases

See: [CUSTOM_WORKFLOW.md](CUSTOM_WORKFLOW.md) for development guidelines.

---

## ğŸ¤ Contributing

### To This Fork
1. Fork this repository (NicoLeeVaz/ai-data-science-team)
2. Create feature branch: `git checkout -b feature/my-feature`
3. Work in `custom/` directory for new features
4. Submit PR to this fork

### To Original Package
For improvements to the core package, submit PRs to:
- **Upstream:** [business-science/ai-data-science-team](https://github.com/business-science/ai-data-science-team)

---

## ğŸ“Š Examples Gallery

### Data Quality Validation
```python
from custom.agents import DataQualityAgent

agent = DataQualityAgent(model=llm)
report = agent.generate_report(df, "customer_data")

# Output:
# DATA QUALITY SCORECARD
# ================================================
# Overall Quality Score: 87.3/100
#
# Breakdown:
#   Completeness   : 95.2/100 â˜…â˜…â˜…â˜…â˜…
#   Uniqueness     : 89.5/100 â˜…â˜…â˜…â˜…â˜†
#   Validity       : 82.1/100 â˜…â˜…â˜…â˜…â˜†
#   Consistency    : 82.5/100 â˜…â˜…â˜…â˜…â˜†
```

### Feature Importance Analysis
```python
from custom.agents import FeatureImportanceAgent

agent = FeatureImportanceAgent(model=llm)
importance = agent.quick_importance(model, feature_names)

# Output:
# TOP 20 MOST IMPORTANT FEATURES:
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Rank   Feature                    Importance
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1      customer_lifetime_value    0.234567
# 2      purchase_frequency         0.198234
# 3      avg_order_value           0.156789
```

### Model Comparison
```python
from custom.agents import ModelComparisonAgent

agent = ModelComparisonAgent(model=llm)
results = agent.quick_comparison(predictions, y_test, models, 'classification')

# Output:
# BEST MODELS PER METRIC:
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   accuracy       : RandomForest         (0.9234)
#   precision      : GradientBoosting     (0.9156)
#   recall         : RandomForest         (0.9089)
#   f1_score       : RandomForest         (0.9161)
```

---

## ğŸ“ˆ Roadmap

### Planned Features (This Fork)
- [ ] Automated model deployment agent
- [ ] A/B testing comparison tools
- [ ] Advanced feature selection algorithms
- [ ] Causal inference tools
- [ ] Drift detection for deployed models

### Staying Updated with Upstream
```bash
# Pull latest from original package
git fetch upstream main
git merge upstream/main

# Your custom/ directory won't conflict!
```

---

## ğŸ“„ License

Same as original: **MIT License**

This fork maintains the MIT license from the original project. You're free to use, modify, and distribute both the original package features and custom extensions.

---

## ğŸ™ Acknowledgments

**Original Package:** [business-science/ai-data-science-team](https://github.com/business-science/ai-data-science-team) by Matt Dancho

**This Fork:** Enhanced with custom agents for comprehensive data science workflows

---

## ğŸ“ Support

### For Custom Extensions (This Fork)
- Issues: [NicoLeeVaz/ai-data-science-team/issues](https://github.com/NicoLeeVaz/ai-data-science-team/issues)
- Documentation: `custom/docs/CUSTOM_EXTENSIONS_GUIDE.md`
- Examples: `custom/examples/`

### For Original Package Features
- Issues: [business-science/ai-data-science-team/issues](https://github.com/business-science/ai-data-science-team/issues)
- Documentation: See main [README.md](README.md)

---

## â­ Star This Fork!

If you find these custom extensions useful, please star this repository!

[â­ Star on GitHub](https://github.com/NicoLeeVaz/ai-data-science-team)

---

**Quick Links:**
- [Custom Extensions Guide](custom/docs/CUSTOM_EXTENSIONS_GUIDE.md)
- [Usage Examples](custom/examples/README.md)
- [Development Workflow](CUSTOM_WORKFLOW.md)
- [Original README](README.md)
