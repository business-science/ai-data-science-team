{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervisor Data Science Team\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Supervised Teams of Agents for Data Science\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Table of Contents\n",
        "\n",
        "1. [Supervisor Data Science Team](#supervisor-data-science-team)\n",
        "2. [Supervised Teams of Agents for Data Science](#supervised-teams-of-agents-for-data-science)\n",
        "3. [Load Libraries](#load-libraries)\n",
        "4. [Setup AI and Logging](#setup-ai-and-logging)\n",
        "5. [Load a Dataset](#load-a-dataset)\n",
        "6. [Create The Team](#create-the-team)\n",
        "7. [Run the Team](#run-the-team)\n",
        "    1. [Example 1: Clean and summarize churn](#example-1-clean-and-summarize-churn)\n",
        "    2. [Example 2: Visualize churn by contract](#example-2-visualize-churn-by-contract)\n",
        "8. [Response](#response)\n",
        "9. [Artifacts](#artifacts)\n",
        "10. [Plotly Graph](#plotly-graph)\n",
        "11. [Want To Become A Full-Stack Generative AI Data Scientist?](#want-to-become-a-full-stack-generative-ai-data-scientist)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# * Libraries\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import sqlalchemy as sql\n",
        "\n",
        "from ai_data_science_team.agents import (\n",
        "    DataLoaderToolsAgent,\n",
        "    DataWranglingAgent,\n",
        "    DataCleaningAgent,\n",
        "    DataVisualizationAgent,\n",
        "    SQLDatabaseAgent,\n",
        "    FeatureEngineeringAgent,\n",
        "    WorkflowPlannerAgent,\n",
        ")\n",
        "from ai_data_science_team.ds_agents import EDAToolsAgent\n",
        "from ai_data_science_team.ml_agents import H2OMLAgent, MLflowToolsAgent, ModelEvaluationAgent\n",
        "from ai_data_science_team.multiagents.supervisor_ds_team import SupervisorDSTeam\n",
        "from ai_data_science_team.utils.plotly import plotly_from_dict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup AI and Logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x30b35b6d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x30bb1be80>, root_client=<openai.OpenAI object at 0x30b35ada0>, root_async_client=<openai.AsyncOpenAI object at 0x30bb1bdc0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# * Setup\n",
        "\n",
        "MODEL    = \"gpt-4.1-mini\"\n",
        "LOG      = False\n",
        "LOG_PATH = os.path.join(os.getcwd(), \"logs/\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = yaml.safe_load(open('../credentials.yml'))['openai']\n",
        "\n",
        "llm = ChatOpenAI(model = MODEL)\n",
        "\n",
        "llm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load a Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'data/churn_data.csv'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dataset path used by the supervisor team\n",
        "\n",
        "DATA_PATH = \"data/churn_data.csv\"\n",
        "DATA_PATH\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create The Team\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ai_data_science_team.multiagents.supervisor_ds_team.SupervisorDSTeam at 0x30c02e110>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# SQL connection (used if the team needs SQL)\n",
        "\n",
        "sql_engine = sql.create_engine(\"sqlite:///data/northwind.db\")\n",
        "conn = sql_engine.connect()\n",
        "\n",
        "# Sub-agents\n",
        "workflow_planner_agent = WorkflowPlannerAgent(llm, log=LOG)\n",
        "\n",
        "data_loader_agent = DataLoaderToolsAgent(\n",
        "    llm,\n",
        "    invoke_react_agent_kwargs={\"recursion_limit\": 4},\n",
        ")\n",
        "\n",
        "data_wrangling_agent = DataWranglingAgent(\n",
        "    model=llm,\n",
        "    log=LOG,\n",
        "    log_path=LOG_PATH,\n",
        ")\n",
        "\n",
        "data_cleaning_agent = DataCleaningAgent(\n",
        "    model=llm,\n",
        "    log=LOG,\n",
        "    log_path=LOG_PATH,\n",
        ")\n",
        "\n",
        "eda_tools_agent = EDAToolsAgent(\n",
        "    model=llm,\n",
        ")\n",
        "\n",
        "data_visualization_agent = DataVisualizationAgent(\n",
        "    model=llm,\n",
        "    log=LOG,\n",
        "    log_path=LOG_PATH,\n",
        ")\n",
        "\n",
        "sql_database_agent = SQLDatabaseAgent(\n",
        "    model=llm,\n",
        "    connection=conn,\n",
        "    log=LOG,\n",
        "    log_path=LOG_PATH,\n",
        ")\n",
        "\n",
        "feature_engineering_agent = FeatureEngineeringAgent(\n",
        "    model=llm,\n",
        "    log=LOG,\n",
        "    log_path=LOG_PATH,\n",
        ")\n",
        "\n",
        "h2o_ml_agent = H2OMLAgent(\n",
        "    model=llm,\n",
        "    log=LOG,\n",
        "    log_path=LOG_PATH,\n",
        ")\n",
        "\n",
        "model_evaluation_agent = ModelEvaluationAgent()\n",
        "\n",
        "mlflow_tools_agent = MLflowToolsAgent(\n",
        "    model=llm,\n",
        "    log_tool_calls=True,\n",
        ")\n",
        "\n",
        "# Supervisor team\n",
        "team = SupervisorDSTeam(\n",
        "    model=llm,\n",
        "    workflow_planner_agent=workflow_planner_agent,\n",
        "    data_loader_agent=data_loader_agent,\n",
        "    data_wrangling_agent=data_wrangling_agent,\n",
        "    data_cleaning_agent=data_cleaning_agent,\n",
        "    eda_tools_agent=eda_tools_agent,\n",
        "    data_visualization_agent=data_visualization_agent,\n",
        "    sql_database_agent=sql_database_agent,\n",
        "    feature_engineering_agent=feature_engineering_agent,\n",
        "    h2o_ml_agent=h2o_ml_agent,\n",
        "    mlflow_tools_agent=mlflow_tools_agent,\n",
        "    model_evaluation_agent=model_evaluation_agent,\n",
        "    temperature=1.0,\n",
        ")\n",
        "\n",
        "team\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the Team\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Clean and summarize churn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---SUPERVISOR---\n",
            "  next_step='load' -> Data_Loader_Tools_Agent\n",
            "---DATA LOADER---\n",
            "---DATA LOADER TOOLS AGENT----\n",
            "    * PREPARE MESSAGES\n",
            "    * RUN REACT TOOL-CALLING AGENT\n",
            "    * Tool: load_file | data/churn_data.csv\n",
            "    * POST-PROCESS RESULTS\n",
            "    * Tool: load_file | data/churn_data.csv\n",
            "    * Artifacts captured: ['load_file']\n",
            "  loader data_raw shape=(21, 5000) active_data_key=data_raw\n",
            "---SUPERVISOR---\n",
            "  next_step='clean' -> Data_Cleaning_Agent\n",
            "---DATA CLEANING---\n",
            "---DATA CLEANING AGENT----\n",
            "    * RECOMMEND CLEANING STEPS\n",
            "    * CREATE DATA CLEANER CODE\n",
            "    * EXECUTE DATA CLEANER CODE (SANDBOXED)\n",
            "    * FIX AGENT CODE\n",
            "      retry_count:0\n",
            "    * EXECUTE DATA CLEANER CODE (SANDBOXED)\n",
            "    * FIX AGENT CODE\n",
            "      retry_count:1\n",
            "    * EXECUTE DATA CLEANER CODE (SANDBOXED)\n",
            "    * FIX AGENT CODE\n",
            "      retry_count:2\n",
            "    * EXECUTE DATA CLEANER CODE (SANDBOXED)\n",
            "    * REPORT AGENT OUTPUTS\n",
            "---SUPERVISOR---\n",
            "  step 'clean' already attempted -> FINISH\n"
          ]
        }
      ],
      "source": [
        "team.invoke_agent(\n",
        "    user_instructions=(\n",
        "        f\"Load the churn data at path {DATA_PATH}, \"\n",
        "        \"clean it (do not remove outliers), \"\n",
        "        \"and give me a short churn rate summary table.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "artifacts = team.get_artifacts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The churn data from \"data/churn_data.csv\" has been loaded and cleaned without removing outliers. Imputation and necessary cleaning steps were performed. A short churn rate summary table is provided below.\n",
              "\n",
              "| Churn Rate | Percentage |\n",
              "|------------|------------|\n",
              "| Churned    | 26.54%     |\n",
              "| Retained   | 73.46%     |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "team.get_ai_message(markdown=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Artifacts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['data_loader', 'data_cleaning']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(artifacts.keys()) if artifacts else None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Visualize churn by contract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "team.invoke_agent(\n",
        "    user_instructions=(\n",
        "        \"Using the cleaned dataset, plot churn rate by Contract as a bar chart.\"\n",
        "    ),\n",
        "    artifacts=artifacts,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plotly Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotly_from_dict(team.response.get(\"viz_graph\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Want To Become A Full-Stack Generative AI Data Scientist?\n",
        "\n",
        "![Generative AI Data Scientist](../../img/become_a_generative_ai_data_scientist.jpg)\n",
        "\n",
        "I teach Generative AI Data Science to help you build AI-powered data science apps. [**Register for my next Generative AI for Data Scientists workshop here.**](https://learn.business-science.io/ai-register)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ds4b_301p_dev_langchain_latest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
