{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Automate Data Cleaning with AI <a id=\"make-a-data-cleaning-agent\"></a>\n",
    "\n",
    "In this tutorial, you will learn how to automate data cleaning with AI. It can automatically:\n",
    "\n",
    "- detect and fix common data cleaning issues\n",
    "- missing values\n",
    "- duplicate rows\n",
    "- inconsistent data types. \n",
    " \n",
    "By using this AI agent, you can save time and effort on data cleaning, allowing you to focus on more important tasks.\n",
    "\n",
    "### Want To Become A Full-Stack Generative AI Data Scientist?\n",
    "\n",
    "![Generative AI Data Scientist](../img/become_a_generative_ai_data_scientist.jpg)\n",
    "\n",
    "I teach Generative AI Data Science to help you build AI-powered data science apps. [**Register for my next Generative AI for Data Scientists workshop here.**](https://learn.business-science.io/ai-register)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Make A Data Cleaning Agent](#make-a-data-cleaning-agent)\n",
    "2. [Load Libraries](#load-libraries)\n",
    "3. [Setup AI and Logging](#setup-ai-and-logging)\n",
    "4. [Load a Dataset](#load-a-dataset)\n",
    "5. [Create The Agent](#create-the-agent)\n",
    "6. [Response](#response)\n",
    "7. [The cleaning recipe](#the-cleaning-recipe)\n",
    "8. [Data Cleaner Function](#data-cleaner-function)\n",
    "9. [Cleaned Data As Pandas Data Frame](#cleaned-data-as-pandas-data-frame)\n",
    "10. [Free Generative AI Data Science Workshop](#free-generative-ai-data-science-workshop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries <a id=\"load-libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Cakekritsanan/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# * Libraries\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from ai_data_science_team.agents import DataCleaningAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup AI and Logging <a id=\"setup-ai-and-logging\"></a>\n",
    "\n",
    "This section of code sets up the LLM inputs and the logging information. Logging is used to store AI-generated code and files during the AI Data Science Teams processing of files. \n",
    "\n",
    "*Important Note:* This example uses OpenAI's API. But any LLM can be used such as Anthropic or local LLMs with Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Setup\n",
    "\n",
    "MODEL    = \"gpt-4o-mini\"\n",
    "LOG      = True\n",
    "LOG_PATH = os.path.join(os.getcwd(), \"logs/\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = yaml.safe_load(open('../credentials.yml'))['openai']\n",
    "\n",
    "llm = ChatOpenAI(model = MODEL)\n",
    "\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Dataset <a id=\"load-a-dataset\"></a>\n",
    "\n",
    "Next, let's load a customer churn data set that we will clean up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/business-science/ai-data-science-team/refs/heads/master/data/churn_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Agent <a id=\"create-the-agent\"></a>\n",
    "\n",
    "Run this code to create an agent with `make_data_cleaning_agent()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning_agent = DataCleaningAgent(\n",
    "    model = llm, \n",
    "    log=LOG, \n",
    "    log_path=LOG_PATH\n",
    ")\n",
    "\n",
    "data_cleaning_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates an `app`, which is a langgraph agent with the main inputs:\n",
    "\n",
    "- **user_instructions**: The data cleaning agent will use these comments to modify the \"standard recipe\" \n",
    "  - Standard Recipe: The standard cleaning recipe which includes removing columns with more than 40% missing values, imputing missing values using mean (numeric) or mode (categorical), removing duplicate rows, and removing outliers. \n",
    "- **data_raw**: The raw data to be cleaned\n",
    "- **max_retries**: Used to limit the number of attempts to fix the python code generated by the agent. Set this to 3 to limit to 3 attempts. \n",
    "- **retry_count**: Set this to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning_agent.invoke_agent(\n",
    "    data_raw=df,\n",
    "    user_instructions=\"Don't remove outliers when cleaning the data.\",\n",
    "    max_retries=3,\n",
    "    retry_count=0\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response <a id=\"response\"></a>\n",
    "\n",
    "The response produced contains everything we need to understand the data cleaning decisions made and get the cleaned dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = data_cleaning_agent.get_response()\n",
    "\n",
    "list(response.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaned Data As Pandas Data Frame <a id=\"cleaned-data-as-pandas-data-frame\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `get_data_cleaned()` method to get the cleaned data as a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning_agent.get_data_cleaned()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaner Function <a id=\"data-cleaner-function\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `get_data_cleaner_function()` method to get the data cleaner function pipeline. \n",
    "\n",
    "- In Jupyter Notebooks, setting `markdown=True` will return the function as markdown code. \n",
    "- In Streamlit apps, it's recommended to set `markdown=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning_agent.get_data_cleaner_function(markdown=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommended Steps\n",
    "\n",
    "To get the recommended steps during the data analysis (prior to coding), run the `get_recommended_steps()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning_agent.get_recommended_cleaning_steps(markdown=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want To Become A Full-Stack Generative AI Data Scientist?\n",
    "\n",
    "![Generative AI Data Scientist](../img/become_a_generative_ai_data_scientist.jpg)\n",
    "\n",
    "I teach Generative AI Data Science to help you build AI-powered data science apps. [**Register for my next Generative AI for Data Scientists workshop here.**](https://learn.business-science.io/ai-register)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
